{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máster en Big Data y Data Science\n",
    "\n",
    "### Metodologías de gestión y diseño de proyectos de big data\n",
    "\n",
    "#### AP1 - Preparación de los datos\n",
    "\n",
    "---\n",
    "\n",
    "En esta libreta se realizan las transforamciones sobre los datasets del escenario en función \n",
    "de los resultados de la verificación de calidad de datos. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importan las librerias a utilizar\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "##### Lectura de los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_creditos = pd.read_csv(\"../../data/processed/datos_creditos_mc.csv\", sep=\";\")\n",
    "display(df_creditos.head(1))\n",
    "\n",
    "df_tarjetas = pd.read_csv(\"../../data/processed/datos_tarjetas_mc.csv\", sep=\";\")\n",
    "display(df_tarjetas.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Aplicación de transformaciones\n",
    "\n",
    "**Operaciones a realizar**\n",
    "\n",
    "1. Selección de columnas\n",
    "2. Filtrado de filas\n",
    "3. Construcción de atributos\n",
    "4. Integración de datasets\n",
    "5. Formateo definitivo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Selección de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se establece qué columnas se eliminan\n",
    "\n",
    "# col_eliminar_creditos = []\n",
    "col_eliminar_tarjetas = ['nivel_tarjeta']\n",
    "\n",
    "# Se ejecuta la operación\n",
    "\n",
    "# df_creditos.drop(col_eliminar_creditos, inplace=True, axis=1)\n",
    "df_tarjetas.drop(col_eliminar_tarjetas, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vista del dataset de datos de créditos:\")\n",
    "display(df_creditos.head(1))\n",
    "\n",
    "print(\"Vista del dataset de datos de tarjetas:\")\n",
    "display(df_tarjetas.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza de los datos (filtrado a nivel de filas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se puede definir una función para aplicar los cálculos\n",
    "def regla_pct_ingresos_credito(row):\n",
    "    pct_ingreso = row.pct_ingreso\n",
    "    ingresos = row.ingresos\n",
    "    \n",
    "    if pct_ingreso > 0.5 and ingresos <= 20000:\n",
    "        # Es un error, no cumple la regla definida\n",
    "        return 'err'\n",
    "    else:\n",
    "        return 'ok'\n",
    "\n",
    "\n",
    "# Se aplica la función para todos los elementos del dataset\n",
    "regla_pct_ingresos = df_creditos.apply(lambda row: regla_pct_ingresos_credito(row), axis=1).rename(\"regla_pct_ingresos\")\n",
    "\n",
    "# Se unen los resultados al dataset inicial\n",
    "df_creditos = pd.concat([df_creditos, regla_pct_ingresos], axis=1)\n",
    "df_creditos.head(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se filtran las filas con algún error detectado\n",
    "print(f\"Filas antes del filtro: {df_creditos.shape[0]}\")\n",
    "\n",
    "temp = df_creditos[df_creditos['edad'] < 90]\n",
    "temp_2 = temp[temp['antiguedad_empleado'] < 100]\n",
    "\n",
    "# Otro filtro posible: por la regla de negocio agregada\n",
    "\n",
    "temp_c = temp_2[temp_2['regla_pct_ingresos'] == 'ok']\n",
    "\n",
    "print(f\"Filas después del filtro: {temp_c.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_integrado = pd.merge(temp_c, df_tarjetas, on='id_cliente', how='inner')\n",
    "coincidencias = df_integrado.shape[0]\n",
    "\n",
    "print(f\"Filas del dataset integrado con los filtros realizados: {coincidencias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cantidad de columnas del dataset integrado: {df_integrado.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación de atributos\n",
    "\n",
    "Atributos nominales que se modifican los valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columna: estado_civil\n",
    "cambios_estado_civil = {\n",
    "    'CASADO' : 'C',\n",
    "    'SOLTERO' : 'S',\n",
    "    'DESCONOCIDO' : 'N',\n",
    "    'DIVORCIADO' : 'D',\n",
    "}\n",
    "\n",
    "estado_civil_N = df_integrado.loc[:, ('estado_civil')].map(cambios_estado_civil).rename('estado_civil_N')\n",
    "\n",
    "# Columna: estado_credito\n",
    "cambios_estado_credito = {\n",
    "    0: 'P',\n",
    "    1 : 'C',\n",
    "}\n",
    "\n",
    "estado_credito_N = df_integrado.loc[:, ('estado_credito')].map(cambios_estado_credito).rename('estado_credito_N')\n",
    "\n",
    "# Sobre este resultado será necesario eliminar las columnas auxiliares\n",
    "df_final = pd.concat([estado_civil_N, estado_credito_N, df_integrado], axis=1)\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos numéricos que se discretizan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_integrado['operaciones_ult_12m'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antiguedad del empleado\n",
    "\n",
    "etiquetas_a_e = ['menor_5', '5_a_10', 'mayor_10']\n",
    "rangos_a_e = [0, 4, 10, 50]\n",
    "valor_para_nan = 'NA'\n",
    "antiguedad_empleados_N = pd.cut(df_integrado['antiguedad_empleado'], \n",
    "                                bins=rangos_a_e, \n",
    "                                labels=etiquetas_a_e,\n",
    "                                right=False).cat.add_categories(valor_para_nan).fillna(valor_para_nan)\n",
    "\n",
    "antiguedad_empleados_N.value_counts()\n",
    "\n",
    "# edad\n",
    "\n",
    "etiquetas_e = ['menor_25', '25_a_30']\n",
    "rangos_e = [0, 24, 50]\n",
    "edad_N = pd.cut(df_integrado['edad'], \n",
    "                                bins=rangos_e, \n",
    "                                labels=etiquetas_e)\n",
    "\n",
    "edad_N.value_counts()\n",
    "\n",
    "# pct_ingreso\n",
    "\n",
    "etiquetas_p_i = ['hasta_20', '20_a_40', '40_a_60', 'mayor_60']\n",
    "rangos_p_i = [0, 0.19, 0.39, 0.60, 0.99]\n",
    "pct_ingreso_N = pd.cut(df_integrado['pct_ingreso'], \n",
    "                                bins=rangos_p_i, \n",
    "                                labels=etiquetas_p_i)\n",
    "\n",
    "pct_ingreso_N.value_counts()\n",
    "\n",
    "# ingresos\n",
    "\n",
    "etiquetas_i = ['hasta_20k', '20k_a_50k', '50k_a_100k', 'mayor_100k']\n",
    "rangos_i = [0, 19999, 49999, 99999, 999999]\n",
    "ingresos_N = pd.cut(df_integrado['ingresos'], \n",
    "                                bins=rangos_i, \n",
    "                                labels=etiquetas_i)\n",
    "\n",
    "ingresos_N.value_counts()\n",
    "\n",
    "# tasa_interes\n",
    "\n",
    "etiquetas_t_i = ['hasta_7p', '7p_a_15p', '15p_a_20p', 'mayor_20p']\n",
    "rangos_t_i = [0, 6.99, 14.99, 19.99, 100]\n",
    "tasa_interes_N = pd.cut(df_integrado['tasa_interes'], \n",
    "                                bins=rangos_t_i, \n",
    "                                labels=etiquetas_t_i)\n",
    "\n",
    "tasa_interes_N.value_counts()\n",
    "\n",
    "# antiguedad_cliente\n",
    "\n",
    "etiquetas_a_c = ['menor_2y', '2y_a_4y', 'mayor_4y']\n",
    "rangos_a_c = [0, 24, 48, 100]\n",
    "antiguedad_cliente_N = pd.cut(df_integrado['antiguedad_cliente'], \n",
    "                                bins=rangos_a_c, \n",
    "                                labels=etiquetas_a_c)\n",
    "\n",
    "antiguedad_cliente_N.value_counts()\n",
    "\n",
    "# limite_credito_tc\n",
    "\n",
    "etiquetas_l_tc = ['menor_3k', '3k_a_5k', '5k_a_10k', 'mayor_10k']\n",
    "rangos_l_tc = [0, 2999, 4999, 9999, 100000]\n",
    "limite_credito_tc_N = pd.cut(df_integrado['limite_credito_tc'], \n",
    "                                bins=rangos_l_tc, \n",
    "                                labels=etiquetas_l_tc)\n",
    "\n",
    "limite_credito_tc_N.value_counts()\n",
    "\n",
    "# gastos_ult_12m\n",
    "\n",
    "etiquetas_g_u12 = ['menor_1k', '2k_a_4k', '4k_a_6k', '6k_a_8k', '8k_a_10k', 'mayor_10k']\n",
    "rangos_g_u12 = [0, 999, 3999, 5999, 7999, 9999, 100000]\n",
    "gastos_ult_12m_N = pd.cut(df_integrado['gastos_ult_12m'], \n",
    "                                bins=rangos_g_u12, \n",
    "                                labels=etiquetas_g_u12)\n",
    "\n",
    "gastos_ult_12m_N.value_counts()\n",
    "\n",
    "# operaciones_ult_12m\n",
    "\n",
    "etiquetas_o_u12 = ['menor_15', '15_a_30', '30_a_50', '50_a_75', '75_a_100', 'mayor_100']\n",
    "rangos_o_u12 = [0, 14, 29, 49, 74, 99, 1000]\n",
    "operaciones_ult_12m_N = pd.cut(df_integrado['operaciones_ult_12m'], \n",
    "                                bins=rangos_o_u12, \n",
    "                                labels=etiquetas_o_u12)\n",
    "\n",
    "operaciones_ult_12m_N.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar en este listado otros atributos que pudieran discretizarse o transformarse\n",
    "col_eliminar_final = [\n",
    "              'edad',\n",
    "              'estado_civil',\n",
    "              'estado_credito',\n",
    "              'antiguedad_empleado',\n",
    "              'antiguedad_cliente', \n",
    "              'ingresos',\n",
    "              'pct_ingreso', \n",
    "              'tasa_interes',\n",
    "              'regla_pct_ingresos',\n",
    "              'gastos_ult_12m', \n",
    "              'limite_credito_tc', \n",
    "              'operaciones_ult_12m',\n",
    "              'id_cliente']\n",
    "\n",
    "df_final.drop(col_eliminar_final, inplace=True, axis=1)\n",
    "\n",
    "df_final = pd.concat([operaciones_ult_12m_N, \n",
    "                      gastos_ult_12m_N, \n",
    "                      limite_credito_tc_N, \n",
    "                      antiguedad_cliente_N, \n",
    "                      tasa_interes_N, \n",
    "                      ingresos_N, \n",
    "                      pct_ingreso_N, \n",
    "                      antiguedad_empleados_N, \n",
    "                      edad_N, \n",
    "                      df_final], axis=1)\n",
    "df_final.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportación de metadatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtale as dt\n",
    "\n",
    "informe = dt.show(df_final)\n",
    "informe.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cantidad de columnas del dataset final: {df_final.shape[1]}\")\n",
    "print(f\"Cantidad de filas del dataset final: {df_final.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"../../data/final/datos_finales.csv\", sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
